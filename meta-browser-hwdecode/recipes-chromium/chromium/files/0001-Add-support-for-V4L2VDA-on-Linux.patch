From 82c3595535926d2986ed577bcc3ae0db1fe2ac20 Mon Sep 17 00:00:00 2001
From: Damian Hobson-Garcia <dhobsong@igel.co.jp>
Date: Tue, 10 Oct 2017 11:34:22 +0900
Subject: [PATCH 1/3] Add support for V4L2VDA on Linux

---
 media/gpu/BUILD.gn                                 | 29 +++++++++++-----------
 media/gpu/args.gni                                 |  4 +++
 media/gpu/generic_v4l2_device.cc                   |  2 +-
 media/gpu/gpu_video_decode_accelerator_factory.cc  | 14 ++++++++++-
 media/gpu/gpu_video_decode_accelerator_factory.h   |  4 ++-
 ...gpu_jpeg_decode_accelerator_factory_provider.cc |  2 +-
 media/gpu/v4l2_device.cc                           | 23 ++++++++++++++++-
 media/gpu/v4l2_video_decode_accelerator.cc         |  6 ++++-
 8 files changed, 64 insertions(+), 20 deletions(-)

diff --git a/media/gpu/BUILD.gn b/media/gpu/BUILD.gn
index 613e830..797e86a 100644
--- a/media/gpu/BUILD.gn
+++ b/media/gpu/BUILD.gn
@@ -16,6 +16,7 @@ buildflag_header("features") {
     "USE_VAAPI=$use_vaapi",
     "USE_V4L2_CODEC=$use_v4l2_codec",
     "USE_LIBV4L2=$use_v4lplugin",
+    "USE_LINUX_V4L2=$use_linux_v4l2_only",
     "ENABLE_MEDIA_CODEC_VIDEO_DECODER=$enable_media_codec_video_decoder",
   ]
 }
@@ -66,7 +67,7 @@ if (use_vaapi) {
   }
 }
 
-if (is_chromeos && use_v4lplugin) {
+if (use_v4lplugin) {
   action("libv4l2_generate_stubs") {
     extra_header = "v4l2_stub_header.fragment"
 
@@ -259,16 +260,12 @@ component("gpu") {
     ]
   }
 
-  if (use_v4lplugin) {
-    sources += get_target_outputs(":libv4l2_generate_stubs")
-    deps += [ ":libv4l2_generate_stubs" ]
-  }
-
   if (use_v4l2_codec) {
-    deps += [
-      "//third_party/libyuv",
-      "//ui/ozone",
-    ]
+    if (use_v4lplugin) {
+      sources += get_target_outputs(":libv4l2_generate_stubs")
+      deps += [ ":libv4l2_generate_stubs" ]
+    }
+    deps += [ "//third_party/libyuv" ]
     sources += [
       "generic_v4l2_device.cc",
       "generic_v4l2_device.h",
@@ -276,15 +273,19 @@ component("gpu") {
       "v4l2_device.h",
       "v4l2_image_processor.cc",
       "v4l2_image_processor.h",
-      "v4l2_jpeg_decode_accelerator.cc",
-      "v4l2_jpeg_decode_accelerator.h",
-      "v4l2_slice_video_decode_accelerator.cc",
-      "v4l2_slice_video_decode_accelerator.h",
       "v4l2_video_decode_accelerator.cc",
       "v4l2_video_decode_accelerator.h",
       "v4l2_video_encode_accelerator.cc",
       "v4l2_video_encode_accelerator.h",
     ]
+    if (!use_linux_v4l2_only) {
+      sources += [
+        "v4l2_jpeg_decode_accelerator.cc",
+        "v4l2_jpeg_decode_accelerator.h",
+        "v4l2_slice_video_decode_accelerator.cc",
+        "v4l2_slice_video_decode_accelerator.h",
+      ]
+    }
     libs = [
       "EGL",
       "GLESv2",
diff --git a/media/gpu/args.gni b/media/gpu/args.gni
index df4b0f9..b438086 100644
--- a/media/gpu/args.gni
+++ b/media/gpu/args.gni
@@ -10,6 +10,10 @@ declare_args() {
   # platforms which have v4l2 hardware encoder / decoder.
   use_v4l2_codec = false
 
+  # Indicates that only definitions available in the mainline linux kernel
+  # will be used.
+  use_linux_v4l2_only = true
+
   # Indicates if VA-API-based hardware acceleration is to be used. This
   # is typically the case on x86-based ChromeOS devices.
   use_vaapi = false
diff --git a/media/gpu/generic_v4l2_device.cc b/media/gpu/generic_v4l2_device.cc
index 8804394..b72e53d 100644
--- a/media/gpu/generic_v4l2_device.cc
+++ b/media/gpu/generic_v4l2_device.cc
@@ -465,7 +465,7 @@ bool GenericV4L2Device::OpenDevicePath(const std::string& path, Type type) {
     return false;
 
 #if BUILDFLAG(USE_LIBV4L2)
-  if (type == Type::kEncoder &&
+  if (
       HANDLE_EINTR(v4l2_fd_open(device_fd_.get(), V4L2_DISABLE_CONVERSION)) !=
           -1) {
     DVLOG(2) << "Using libv4l2 for " << path;
diff --git a/media/gpu/gpu_video_decode_accelerator_factory.cc b/media/gpu/gpu_video_decode_accelerator_factory.cc
index 22f8f4a..1235e48 100644
--- a/media/gpu/gpu_video_decode_accelerator_factory.cc
+++ b/media/gpu/gpu_video_decode_accelerator_factory.cc
@@ -20,12 +20,16 @@
 #if defined(OS_MACOSX)
 #include "media/gpu/vt_video_decode_accelerator_mac.h"
 #endif
+#if defined(OS_LINUX)
 #if BUILDFLAG(USE_V4L2_CODEC)
 #include "media/gpu/v4l2_device.h"
+#if !BUILDFLAG(USE_LINUX_V4L2)
 #include "media/gpu/v4l2_slice_video_decode_accelerator.h"
+#endif
 #include "media/gpu/v4l2_video_decode_accelerator.h"
 #include "ui/gl/gl_surface_egl.h"
 #endif
+#endif
 #if defined(OS_ANDROID)
 #include "media/gpu/android/device_info.h"
 #include "media/gpu/android_video_decode_accelerator.h"
@@ -96,10 +100,12 @@ GpuVideoDecodeAcceleratorFactory::GetDecoderCapabilities(
   vda_profiles = V4L2VideoDecodeAccelerator::GetSupportedProfiles();
   GpuVideoAcceleratorUtil::InsertUniqueDecodeProfiles(
       vda_profiles, &capabilities.supported_profiles);
+#if !BUILDFLAG(USE_LINUX_V4L2)
   vda_profiles = V4L2SliceVideoDecodeAccelerator::GetSupportedProfiles();
   GpuVideoAcceleratorUtil::InsertUniqueDecodeProfiles(
       vda_profiles, &capabilities.supported_profiles);
 #endif
+#endif
 #if BUILDFLAG(USE_VAAPI)
   vda_profiles = VaapiVideoDecodeAccelerator::GetSupportedProfiles();
   GpuVideoAcceleratorUtil::InsertUniqueDecodeProfiles(
@@ -111,6 +117,9 @@ GpuVideoDecodeAcceleratorFactory::GetDecoderCapabilities(
 #elif defined(OS_ANDROID)
   capabilities =
       AndroidVideoDecodeAccelerator::GetCapabilities(gpu_preferences);
+#elif defined(OS_LINUX)
+  capabilities.supported_profiles =
+      V4L2VideoDecodeAccelerator::GetSupportedProfiles();
 #endif
   return GpuVideoAcceleratorUtil::ConvertMediaToGpuDecodeCapabilities(
       capabilities);
@@ -141,8 +150,10 @@ GpuVideoDecodeAcceleratorFactory::CreateVDA(
 #endif
 #if BUILDFLAG(USE_V4L2_CODEC)
     &GpuVideoDecodeAcceleratorFactory::CreateV4L2VDA,
+#if !BUILDFLAG(USE_LINUX_V4L2)
     &GpuVideoDecodeAcceleratorFactory::CreateV4L2SVDA,
 #endif
+#endif
 #if BUILDFLAG(USE_VAAPI)
     &GpuVideoDecodeAcceleratorFactory::CreateVaapiVDA,
 #endif
@@ -208,7 +219,7 @@ GpuVideoDecodeAcceleratorFactory::CreateV4L2VDA(
   }
   return decoder;
 }
-
+#if !BUILDFLAG(USE_LINUX_V4L2)
 std::unique_ptr<VideoDecodeAccelerator>
 GpuVideoDecodeAcceleratorFactory::CreateV4L2SVDA(
     const gpu::GpuDriverBugWorkarounds& workarounds,
@@ -223,6 +234,7 @@ GpuVideoDecodeAcceleratorFactory::CreateV4L2SVDA(
   return decoder;
 }
 #endif
+#endif
 
 #if BUILDFLAG(USE_VAAPI)
 std::unique_ptr<VideoDecodeAccelerator>
diff --git a/media/gpu/gpu_video_decode_accelerator_factory.h b/media/gpu/gpu_video_decode_accelerator_factory.h
index b089f6a..42ea80c 100644
--- a/media/gpu/gpu_video_decode_accelerator_factory.h
+++ b/media/gpu/gpu_video_decode_accelerator_factory.h
@@ -98,14 +98,16 @@ class MEDIA_GPU_EXPORT GpuVideoDecodeAcceleratorFactory {
       const gpu::GpuDriverBugWorkarounds& workarounds,
       const gpu::GpuPreferences& gpu_preferences) const;
 #endif
-#if BUILDFLAG(USE_V4L2_CODEC)
+#if defined(OS_LINUX) && BUILDFLAG(USE_V4L2_CODEC)
   std::unique_ptr<VideoDecodeAccelerator> CreateV4L2VDA(
       const gpu::GpuDriverBugWorkarounds& workarounds,
       const gpu::GpuPreferences& gpu_preferences) const;
+#if !BUILDFLAG(USE_LINUX_V4L2)
   std::unique_ptr<VideoDecodeAccelerator> CreateV4L2SVDA(
       const gpu::GpuDriverBugWorkarounds& workarounds,
       const gpu::GpuPreferences& gpu_preferences) const;
 #endif
+#endif
 #if BUILDFLAG(USE_VAAPI)
   std::unique_ptr<VideoDecodeAccelerator> CreateVaapiVDA(
       const gpu::GpuDriverBugWorkarounds& workarounds,
diff --git a/media/gpu/ipc/service/gpu_jpeg_decode_accelerator_factory_provider.cc b/media/gpu/ipc/service/gpu_jpeg_decode_accelerator_factory_provider.cc
index 3b3cfd6..87de887 100644
--- a/media/gpu/ipc/service/gpu_jpeg_decode_accelerator_factory_provider.cc
+++ b/media/gpu/ipc/service/gpu_jpeg_decode_accelerator_factory_provider.cc
@@ -12,7 +12,7 @@
 #include "media/gpu/fake_jpeg_decode_accelerator.h"
 #include "media/gpu/features.h"
 
-#if BUILDFLAG(USE_V4L2_CODEC) && defined(ARCH_CPU_ARM_FAMILY)
+#if BUILDFLAG(USE_V4L2_CODEC) && defined(ARCH_CPU_ARM_FAMILY) && !BUILDFLAG(USE_LINUX_V4L2)
 #define USE_V4L2_JDA
 #endif
 
diff --git a/media/gpu/v4l2_device.cc b/media/gpu/v4l2_device.cc
index 718d566..af4550d 100644
--- a/media/gpu/v4l2_device.cc
+++ b/media/gpu/v4l2_device.cc
@@ -90,6 +90,19 @@ uint32_t V4L2Device::VideoPixelFormatToV4L2PixFmt(VideoPixelFormat format) {
 }
 
 // static
+#if BUILDFLAG(USE_LINUX_V4L2)
+uint32_t V4L2Device::VideoCodecProfileToV4L2PixFmt(VideoCodecProfile profile,
+                                                   bool slice_based) {
+  if (profile >= H264PROFILE_MIN && profile <= H264PROFILE_MAX) {
+    return V4L2_PIX_FMT_H264;
+  } else if (profile >= VP8PROFILE_MIN && profile <= VP8PROFILE_MAX) {
+    return V4L2_PIX_FMT_VP8;
+  } else {
+    LOG(FATAL) << "Add more cases as needed";
+    return 0;
+  }
+}
+#else
 uint32_t V4L2Device::VideoCodecProfileToV4L2PixFmt(VideoCodecProfile profile,
                                                    bool slice_based) {
   if (profile >= H264PROFILE_MIN && profile <= H264PROFILE_MAX) {
@@ -112,6 +125,7 @@ uint32_t V4L2Device::VideoCodecProfileToV4L2PixFmt(VideoCodecProfile profile,
     return 0;
   }
 }
+#endif
 
 // static
 std::vector<VideoCodecProfile> V4L2Device::V4L2PixFmtToVideoCodecProfiles(
@@ -122,7 +136,9 @@ std::vector<VideoCodecProfile> V4L2Device::V4L2PixFmtToVideoCodecProfiles(
 
   switch (pix_fmt) {
     case V4L2_PIX_FMT_H264:
+#if !BUILDFLAG(USE_LINUX_V4L2)
     case V4L2_PIX_FMT_H264_SLICE:
+#endif
       if (is_encoder) {
         // TODO(posciak): need to query the device for supported H.264 profiles,
         // for now choose Main as a sensible default.
@@ -135,16 +151,19 @@ std::vector<VideoCodecProfile> V4L2Device::V4L2PixFmtToVideoCodecProfiles(
       break;
 
     case V4L2_PIX_FMT_VP8:
+#if !BUILDFLAG(USE_LINUX_V4L2)
     case V4L2_PIX_FMT_VP8_FRAME:
+#endif
       min_profile = VP8PROFILE_MIN;
       max_profile = VP8PROFILE_MAX;
       break;
-
+#if !BUILDFLAG(USE_LINUX_V4L2)
     case V4L2_PIX_FMT_VP9:
     case V4L2_PIX_FMT_VP9_FRAME:
       min_profile = VP9PROFILE_MIN;
       max_profile = VP9PROFILE_MAX;
       break;
+#endif
 
     default:
       DVLOG(1) << "Unhandled pixelformat " << std::hex << "0x" << pix_fmt;
@@ -174,8 +193,10 @@ uint32_t V4L2Device::V4L2PixFmtToDrmFormat(uint32_t format) {
     case V4L2_PIX_FMT_RGB32:
       return DRM_FORMAT_ARGB8888;
 
+#if !BUILDFLAG(USE_LINUX_V4L2)
     case V4L2_PIX_FMT_MT21:
       return DRM_FORMAT_MT21;
+#endif
 
     default:
       DVLOG(1) << "Unrecognized format " << std::hex << "0x" << format;
diff --git a/media/gpu/v4l2_video_decode_accelerator.cc b/media/gpu/v4l2_video_decode_accelerator.cc
index e44aefb..f4124e8 100644
--- a/media/gpu/v4l2_video_decode_accelerator.cc
+++ b/media/gpu/v4l2_video_decode_accelerator.cc
@@ -25,6 +25,7 @@
 #include "build/build_config.h"
 #include "media/base/media_switches.h"
 #include "media/gpu/shared_memory_region.h"
+#include "media/gpu/features.h"
 #include "media/video/h264_parser.h"
 #include "ui/gfx/geometry/rect.h"
 #include "ui/gl/gl_context.h"
@@ -67,7 +68,10 @@ namespace media {
 
 // static
 const uint32_t V4L2VideoDecodeAccelerator::supported_input_fourccs_[] = {
-    V4L2_PIX_FMT_H264, V4L2_PIX_FMT_VP8, V4L2_PIX_FMT_VP9,
+    V4L2_PIX_FMT_H264, V4L2_PIX_FMT_VP8,
+#if !BUILDFLAG(USE_LINUX_V4L2)
+    V4L2_PIX_FMT_VP9,
+#endif
 };
 
 struct V4L2VideoDecodeAccelerator::BitstreamBufferRef {
-- 
1.9.1

