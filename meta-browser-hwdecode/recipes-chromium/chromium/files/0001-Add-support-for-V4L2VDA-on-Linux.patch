From 9a7b3f8e24dc7cd073262979549fb6cfb1e5e280 Mon Sep 17 00:00:00 2001
From: Damian Hobson-Garcia <dhobsong@igel.co.jp>
Date: Mon, 23 Jan 2017 16:15:43 +0900
Subject: [PATCH 1/2] Add support for V4L2VDA on Linux

Also use libv4l for decode devices, instead of just encode
---
 BUILD.gn                                | 123 +++++++++++++++++---------------
 args.gni                                |   4 ++
 generic_v4l2_device.cc                  |   2 +-
 gpu_video_decode_accelerator_factory.cc |  16 +++--
 gpu_video_decode_accelerator_factory.h  |   4 +-
 v4l2_device.cc                          |  28 +++++++-
 v4l2_video_decode_accelerator.cc        |   5 +-
 7 files changed, 115 insertions(+), 67 deletions(-)

--- a/media/gpu/BUILD.gn        2017-08-10 17:56:34.097076992 +0900
+++ a/media/gpu/BUILD.gn        2017-08-10 17:57:48.972636766 +0900
@@ -64,7 +64,7 @@ if (use_vaapi) {
   }
 }

-if (is_chromeos && use_v4lplugin) {
+if (use_v4lplugin) {
   action("libv4l2_generate_stubs") {
     extra_header = "v4l2_stub_header.fragment"

@@ -102,12 +102,15 @@ if (is_chromeos && use_v4lplugin) {

 config("gpu_config") {
   defines = []
-  if (is_chromeos && use_v4lplugin) {
+  if (use_v4lplugin) {
     defines += [ "USE_LIBV4L2" ]
   }
-  if (is_chromeos && use_v4l2_codec) {
+  if (use_v4l2_codec) {
     defines += [ "USE_V4L2_CODEC" ]
   }
+  if (use_linux_v4l2_only) {
+    defines += [ "USE_LINUX_V4L2" ]
+  }
 }

 component("gpu") {
@@ -267,38 +270,42 @@ component("gpu") {
       "vp9_picture.cc",
       "vp9_picture.h",
     ]
+  }
+  if (use_v4l2_codec) {
     if (use_v4lplugin) {
       sources += get_target_outputs(":libv4l2_generate_stubs")
       deps += [ ":libv4l2_generate_stubs" ]
     }
-    if (use_v4l2_codec) {
-      deps += [ "//third_party/libyuv" ]
+    deps += [ "//third_party/libyuv" ]
+    sources += [
+      "generic_v4l2_device.cc",
+      "generic_v4l2_device.h",
+      "v4l2_device.cc",
+      "v4l2_device.h",
+      "v4l2_image_processor.cc",
+      "v4l2_image_processor.h",
+      "v4l2_video_decode_accelerator.cc",
+      "v4l2_video_decode_accelerator.h",
+      "v4l2_video_encode_accelerator.cc",
+      "v4l2_video_encode_accelerator.h",
+    ]
+    if (!use_linux_v4l2_only) {
       sources += [
-        "generic_v4l2_device.cc",
-        "generic_v4l2_device.h",
-        "v4l2_device.cc",
-        "v4l2_device.h",
-        "v4l2_image_processor.cc",
-        "v4l2_image_processor.h",
         "v4l2_jpeg_decode_accelerator.cc",
         "v4l2_jpeg_decode_accelerator.h",
         "v4l2_slice_video_decode_accelerator.cc",
         "v4l2_slice_video_decode_accelerator.h",
-        "v4l2_video_decode_accelerator.cc",
-        "v4l2_video_decode_accelerator.h",
-        "v4l2_video_encode_accelerator.cc",
-        "v4l2_video_encode_accelerator.h",
       ]
-      libs = [
-        "EGL",
-        "GLESv2",
+    }
+    libs = [
+      "EGL",
+      "GLESv2",
+    ]
+    if (current_cpu == "arm") {
+      sources += [
+        "tegra_v4l2_device.cc",
+        "tegra_v4l2_device.h",
       ]
-      if (current_cpu == "arm") {
-        sources += [
-          "tegra_v4l2_device.cc",
-          "tegra_v4l2_device.h",
-        ]
-      }
     }
   }

diff --git a/media/gpu/args.gni b/media/gpu/args.gni
index c1511d9..fe213c3 100644
--- a/media/gpu/args.gni
+++ b/media/gpu/args.gni
@@ -10,6 +10,10 @@ declare_args() {
   # platforms which have v4l2 hardware encoder / decoder.
   use_v4l2_codec = false

+  # Indicates that only definitions available in the mainline linux kernel
+  # will be used.
+  use_linux_v4l2_only = true
+
   # Indicates if VA-API-based hardware acceleration is to be used. This
   # is typically the case on x86-based ChromeOS devices.
   use_vaapi = false
diff --git a/media/gpu/generic_v4l2_device.cc b/media/gpu/generic_v4l2_device.cc
index 830d004..1553c46 100644
--- a/media/gpu/generic_v4l2_device.cc
+++ b/media/gpu/generic_v4l2_device.cc
@@ -381,7 +381,7 @@ bool GenericV4L2Device::OpenDevicePath(const std::string& path, Type type) {
     return false;

 #if defined(USE_LIBV4L2)
-  if (type == Type::kEncoder &&
+  if (
       HANDLE_EINTR(v4l2_fd_open(device_fd_.get(), V4L2_DISABLE_CONVERSION)) !=
           -1) {
     DVLOG(2) << "Using libv4l2 for " << path;
diff --git a/media/gpu/gpu_video_decode_accelerator_factory.cc b/media/gpu/gpu_video_decode_accelerator_factory.cc
index a7db56f..b273057 100644
--- a/media/gpu/gpu_video_decode_accelerator_factory.cc
+++ b/media/gpu/gpu_video_decode_accelerator_factory.cc
@@ -14,10 +14,12 @@
 #include "media/gpu/dxva_video_decode_accelerator_win.h"
 #elif defined(OS_MACOSX)
 #include "media/gpu/vt_video_decode_accelerator_mac.h"
-#elif defined(OS_CHROMEOS)
+#elif defined(OS_CHROMEOS) || defined(OS_LINUX)
 #if defined(USE_V4L2_CODEC)
 #include "media/gpu/v4l2_device.h"
+#if !defined(USE_LINUX_V4L2)
 #include "media/gpu/v4l2_slice_video_decode_accelerator.h"
+#endif
 #include "media/gpu/v4l2_video_decode_accelerator.h"
 #include "ui/gl/gl_surface_egl.h"
 #endif
@@ -100,6 +102,9 @@ GpuVideoDecodeAcceleratorFactory::GetDecoderCapabilities(
 #elif defined(OS_ANDROID)
   capabilities =
       AndroidVideoDecodeAccelerator::GetCapabilities(gpu_preferences);
+#elif defined(OS_LINUX)
+  capabilities.supported_profiles =
+      V4L2VideoDecodeAccelerator::GetSupportedProfiles();
 #endif
   return GpuVideoAcceleratorUtil::ConvertMediaToGpuDecodeCapabilities(
       capabilities);
@@ -138,10 +138,12 @@ GpuVideoDecodeAcceleratorFactory::Create
     &GpuVideoDecodeAcceleratorFactory::CreateD3D11VDA,
     &GpuVideoDecodeAcceleratorFactory::CreateDXVAVDA,
 #endif
-#if defined(OS_CHROMEOS) && defined(USE_V4L2_CODEC)
+#if (defined(OS_CHROMEOS) || defined(OS_LINUX)) && defined(USE_V4L2_CODEC)
     &GpuVideoDecodeAcceleratorFactory::CreateV4L2VDA,
+#if !defined(USE_LINUX_V4L2)
     &GpuVideoDecodeAcceleratorFactory::CreateV4L2SVDA,
 #endif
+#endif
 #if BUILDFLAG(USE_VAAPI)
     &GpuVideoDecodeAcceleratorFactory::CreateVaapiVDA,
 #endif
@@ -169,7 +176,7 @@ GpuVideoDecodeAcceleratorFactory::CreateDXVAVDA(
 }
 #endif

-#if defined(OS_CHROMEOS) && defined(USE_V4L2_CODEC)
+#if (defined(OS_CHROMEOS) || defined(OS_LINUX)) && defined(USE_V4L2_CODEC)
 std::unique_ptr<VideoDecodeAccelerator>
 GpuVideoDecodeAcceleratorFactory::CreateV4L2VDA(
     const gpu::GpuDriverBugWorkarounds& workarounds,
@@ -183,7 +190,7 @@ GpuVideoDecodeAcceleratorFactory::CreateV4L2VDA(
   }
   return decoder;
 }
-
+#if !defined(USE_LINUX_V4L2)
 std::unique_ptr<VideoDecodeAccelerator>
 GpuVideoDecodeAcceleratorFactory::CreateV4L2SVDA(
     const gpu::GpuDriverBugWorkarounds& workarounds,
@@ -198,6 +205,7 @@ GpuVideoDecodeAcceleratorFactory::CreateV4L2SVDA(
   return decoder;
 }
 #endif
+#endif

 #if defined(OS_CHROMEOS) && defined(ARCH_CPU_X86_FAMILY)
 std::unique_ptr<VideoDecodeAccelerator>
diff --git a/media/gpu/gpu_video_decode_accelerator_factory.h b/media/gpu/gpu_video_decode_accelerator_factory.h
index 29d1d7a..952f02a 100644
--- a/media/gpu/gpu_video_decode_accelerator_factory.h
+++ b/media/gpu/gpu_video_decode_accelerator_factory.h
@@ -98,14 +98,16 @@ class MEDIA_GPU_EXPORT GpuVideoDecodeAcc
       const gpu::GpuDriverBugWorkarounds& workarounds,
       const gpu::GpuPreferences& gpu_preferences) const;
 #endif
-#if defined(OS_CHROMEOS) && defined(USE_V4L2_CODEC)
+#if (defined(OS_CHROMEOS) || defined(OS_LINUX) && defined(USE_V4L2_CODEC))
   std::unique_ptr<VideoDecodeAccelerator> CreateV4L2VDA(
       const gpu::GpuDriverBugWorkarounds& workarounds,
       const gpu::GpuPreferences& gpu_preferences) const;
+#if !defined(USE_LINUX_V4L2)
   std::unique_ptr<VideoDecodeAccelerator> CreateV4L2SVDA(
       const gpu::GpuDriverBugWorkarounds& workarounds,
       const gpu::GpuPreferences& gpu_preferences) const;
 #endif
+#endif
 #if BUILDFLAG(USE_VAAPI)
   std::unique_ptr<VideoDecodeAccelerator> CreateVaapiVDA(
       const gpu::GpuDriverBugWorkarounds& workarounds,
diff --git a/media/gpu/v4l2_device.cc b/media/gpu/v4l2_device.cc
index 3dcd1bf..172946a 100644
--- a/media/gpu/v4l2_device.cc
+++ b/media/gpu/v4l2_device.cc
@@ -87,6 +87,19 @@ uint32_t V4L2Device::VideoPixelFormatToV4L2PixFmt(VideoPixelFormat format) {
 }

 // static
+#ifdef USE_LINUX_V4L2
+uint32_t V4L2Device::VideoCodecProfileToV4L2PixFmt(VideoCodecProfile profile,
+                                                   bool slice_based) {
+  if (profile >= H264PROFILE_MIN && profile <= H264PROFILE_MAX) {
+    return V4L2_PIX_FMT_H264;
+  } else if (profile >= VP8PROFILE_MIN && profile <= VP8PROFILE_MAX) {
+    return V4L2_PIX_FMT_VP8;
+  } else {
+    LOG(FATAL) << "Add more cases as needed";
+    return 0;
+  }
+}
+#else
 uint32_t V4L2Device::VideoCodecProfileToV4L2PixFmt(VideoCodecProfile profile,
                                                    bool slice_based) {
   if (profile >= H264PROFILE_MIN && profile <= H264PROFILE_MAX) {
@@ -109,6 +122,7 @@ uint32_t V4L2Device::VideoCodecProfileToV4L2PixFmt(VideoCodecProfile profile,
     return 0;
   }
 }
+#endif

 // static
 std::vector<VideoCodecProfile> V4L2Device::V4L2PixFmtToVideoCodecProfiles(
@@ -119,7 +133,9 @@ std::vector<VideoCodecProfile> V4L2Device::V4L2PixFmtToVideoCodecProfiles(

   switch (pix_fmt) {
     case V4L2_PIX_FMT_H264:
+#ifndef USE_LINUX_V4L2
     case V4L2_PIX_FMT_H264_SLICE:
+#endif
       if (is_encoder) {
         // TODO(posciak): need to query the device for supported H.264 profiles,
         // for now choose Main as a sensible default.
@@ -132,16 +148,19 @@ std::vector<VideoCodecProfile> V4L2Device::V4L2PixFmtToVideoCodecProfiles(
       break;

     case V4L2_PIX_FMT_VP8:
+#ifndef USE_LINUX_V4L2
     case V4L2_PIX_FMT_VP8_FRAME:
+#endif
       min_profile = VP8PROFILE_MIN;
       max_profile = VP8PROFILE_MAX;
       break;
-
+#ifndef USE_LINUX_V4L2
     case V4L2_PIX_FMT_VP9:
     case V4L2_PIX_FMT_VP9_FRAME:
       min_profile = VP9PROFILE_MIN;
       max_profile = VP9PROFILE_MAX;
       break;
+#endif

     default:
       DVLOG(1) << "Unhandled pixelformat " << std::hex << "0x" << pix_fmt;
@@ -154,6 +173,11 @@ std::vector<VideoCodecProfile> V4L2Device::V4L2PixFmtToVideoCodecProfiles(
   return profiles;
 }

+#ifdef USE_LINUX_V4L2
+#undef V4L2_PIX_FMT_H264_SLICE
+#undef V4L2_PIX_FMT_VP8_FRAME
+#endif
+
 // static
 uint32_t V4L2Device::V4L2PixFmtToDrmFormat(uint32_t format) {
   switch (format) {
@@ -171,8 +195,10 @@ uint32_t V4L2Device::V4L2PixFmtToDrmFormat(uint32_t format) {
     case V4L2_PIX_FMT_RGB32:
       return DRM_FORMAT_ARGB8888;

+#ifndef USE_LINUX_V4L2
     case V4L2_PIX_FMT_MT21:
       return DRM_FORMAT_MT21;
+#endif

     default:
       DVLOG(1) << "Unrecognized format " << std::hex << "0x" << format;
diff --git a/media/gpu/v4l2_video_decode_accelerator.cc b/media/gpu/v4l2_video_decode_accelerator.cc
index 045de39..82ea8fc 100644
--- a/media/gpu/v4l2_video_decode_accelerator.cc
+++ b/media/gpu/v4l2_video_decode_accelerator.cc
@@ -66,7 +66,10 @@ namespace media {

 // static
 const uint32_t V4L2VideoDecodeAccelerator::supported_input_fourccs_[] = {
-    V4L2_PIX_FMT_H264, V4L2_PIX_FMT_VP8, V4L2_PIX_FMT_VP9,
+    V4L2_PIX_FMT_H264, V4L2_PIX_FMT_VP8
+#ifndef USE_LINUX_V4L2
+    V4L2_PIX_FMT_VP9,
+#endif
 };

 struct V4L2VideoDecodeAccelerator::BitstreamBufferRef {
--
1.9.1

